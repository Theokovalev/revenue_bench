# Revenue Bench - Complete Model Outputs

This directory contains outputs from **33 of 33** models evaluated.

## Files

- `complete_outputs_all.json` - All {found_count} model outputs
- `model_responses/` - Individual model responses
- `evaluations/` - Detailed evaluation scores

## Leaderboard with Output Status

| Rank | Model | Score | Cost | Has Output |
|------|-------|-------|------|------------|
| 1 | claude-opus-4.1 | 82.5% | $2.09 | ✅ |
| 2 | gpt-5 | 82.1% | $0.08 | ✅ |
| 3 | gemini-2.5-flash | 80.0% | $0.08 | ✅ |
| 4 | claude-opus-4 | 78.8% | $0.98 | ✅ |
| 5 | gpt-oss-120b | 78.7% | $0.00 | ✅ |
| 6 | glm-4.5 | 77.9% | $0.12 | ✅ |
| 7 | grok-4 | 77.5% | $0.31 | ✅ |
| 8 | claude-sonnet-4 | 75.8% | $0.47 | ✅ |
| 9 | kimi-k2 | 74.6% | $0.09 | ✅ |
| 10 | o3 | 73.3% | $0.08 | ✅ |
| 11 | grok-3 | 72.5% | $0.34 | ✅ |
| 12 | glm-4-32b | 72.1% | $0.07 | ✅ |
| 13 | gpt-4.1 | 67.9% | $0.07 | ✅ |
| 14 | gpt-5-mini | 64.2% | $0.07 | ✅ |
| 15 | gemini-2.5-flash-lite | 62.9% | $0.07 | ✅ |
| 16 | o3-mini | 60.0% | $0.07 | ✅ |
| 17 | qwen3-235b-a22b-thinking-2507 | 54.6% | $0.07 | ✅ |
| 18 | deepseek-r1 | 52.1% | $0.08 | ✅ |
| 19 | qwen3-30b-a3b-instruct-2507 | 51.3% | $0.06 | ✅ |
| 20 | sonar-pro | 47.1% | $0.08 | ✅ |
| 21 | qwen-2.5-72b-instruct | 46.2% | $0.07 | ✅ |
| 22 | gemma-3-27b-it | 45.8% | $0.07 | ✅ |
| 23 | jamba-large-1.7 | 45.4% | $0.07 | ✅ |
| 24 | mixtral-8x22b-instruct | 43.8% | $0.06 | ✅ |
| 25 | llama-3.1-70b-instruct | 43.3% | $0.07 | ✅ |
| 26 | mixtral-8x7b-instruct | 42.9% | $0.06 | ✅ |
| 27 | llama-4-maverick | 40.8% | $0.06 | ✅ |
| 28 | jamba-mini-1.7 | 30.8% | $0.07 | ✅ |
| 29 | gpt-oss-20b | 2.5% | $0.04 | ✅ |
| 30 | gemini-2.5-pro | 2.5% | $0.08 | ✅ |
| 31 | gpt-5-nano | 0.0% | $0.05 | ✅ |
| 32 | grok-3-mini | 0.0% | $0.05 | ✅ |
| 33 | glm-4.5-air:free | 0.0% | $0.05 | ✅ |
