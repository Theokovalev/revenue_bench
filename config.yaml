# Revenue Bench Configuration

# Model configurations
models:
  # Top performers based on evaluation results
  recommended:
    - "openrouter/anthropic/claude-opus-4.1"  # 82.5% score, $2.09/eval
    - "openrouter/openai/gpt-5"               # 82.1% score, $0.08/eval
    - "openrouter/openai/gpt-5-mini"          # 80.5% score, $0.01/eval
    - "openrouter/openai/gpt-4o"              # 79.3% score, $0.05/eval
    - "openrouter/google/gemini-2.5-pro"      # 77.8% score, $0.17/eval
  
  # All available models
  all:
    # OpenAI Models
    - "openrouter/openai/gpt-5"
    - "openrouter/openai/gpt-5-mini"
    - "openrouter/openai/gpt-4o"
    - "openrouter/openai/gpt-4o-mini"
    
    # Anthropic Models
    - "openrouter/anthropic/claude-opus-4.1"
    - "openrouter/anthropic/claude-4-sonnet"
    - "openrouter/anthropic/claude-3.5-sonnet"
    - "openrouter/anthropic/claude-3.5-haiku"
    
    # Google Models
    - "openrouter/google/gemini-2.5-pro"
    - "openrouter/google/gemini-2.5-flash"
    - "openrouter/google/gemini-2.0-flash-thinking-exp-1219"
    
    # DeepSeek Models
    - "openrouter/deepseek/deepseek-chat"
    - "openrouter/deepseek/deepseek-r1-distill-llama-70b"
    
    # Meta Models
    - "openrouter/meta-llama/llama-3.3-70b-instruct"
    - "openrouter/meta-llama/llama-3.1-70b-instruct"
    
    # Other Models
    - "openrouter/moonshotai/kimi-k2"
    - "openrouter/openai/o1"
    - "openrouter/openai/o3-mini"
    - "openrouter/x-ai/grok-2-1212"
    - "openrouter/cohere/command-r-plus-08-2024"
    - "openrouter/mistralai/mistral-large-2411"
    - "openrouter/qwen/qwen-2.5-72b-instruct"

# Judge configuration
judges:
  - "openrouter/google/gemini-2.5-pro"
  - "openrouter/moonshotai/kimi-k2"
  - "openrouter/openai/gpt-5-mini"
  - "openrouter/anthropic/claude-opus-4.1"

# Scoring weights
scoring:
  weights:
    engineering_pain: 0.35  # 35% - Recognition of ops/labor pain
    prospect_insight: 0.30  # 30% - Specific, verifiable details
    product_fit: 0.25      # 25% - Natural connection to Homebase
    reply_probability: 0.10 # 10% - Would they actually reply?
  
  # Verification penalties
  unverified_penalty: 0.8  # Reduce insight score by 80% if not verified

# API settings
api:
  openrouter:
    base_url: "https://openrouter.ai/api/v1"
    timeout: 120  # seconds
    max_retries: 3
  
  tavily:
    base_url: "https://api.tavily.com"
    search_depth: "basic"  # "basic" or "advanced"
    max_results: 5

# Evaluation settings
evaluation:
  batch_size: 3  # Number of prospects per evaluation
  max_tokens: 3000  # Max tokens for model response
  temperature: 0.7  # Model temperature
  
  # Cost tracking
  track_costs: true
  cost_estimates:
    # Approximate costs per 1M tokens
    openai_gpt5: 15.00
    openai_gpt5_mini: 0.60
    anthropic_claude_opus: 75.00
    anthropic_claude_sonnet: 15.00
    google_gemini_pro: 7.00
    google_gemini_flash: 0.30

# Output settings
output:
  format: "json"  # "json" or "csv"
  include_metadata: true
  include_judge_details: true
  save_logs: true